<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Proposal | Optical Music Recognition</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Proposal" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Background Composers, performers and musicians frequently want to make edits, comments, and changes to the sheet music. Doing so traditionally will produce hundreds or thousands of uncluttered pages of sheet music. Digital format is the perfect solution to better organize a collection of sheet music. It ensures replayability, enables large-scale musical theory analysis, and allows users to search for specific content systematically. Therefore, we present an end-to-end system to digitize music collection." />
<meta property="og:description" content="Background Composers, performers and musicians frequently want to make edits, comments, and changes to the sheet music. Doing so traditionally will produce hundreds or thousands of uncluttered pages of sheet music. Digital format is the perfect solution to better organize a collection of sheet music. It ensures replayability, enables large-scale musical theory analysis, and allows users to search for specific content systematically. Therefore, we present an end-to-end system to digitize music collection." />
<link rel="canonical" href="http://localhost:4000/omr/proposal/omr/2019/11/28/proposal.html" />
<meta property="og:url" content="http://localhost:4000/omr/proposal/omr/2019/11/28/proposal.html" />
<meta property="og:site_name" content="Optical Music Recognition" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-11-28T00:57:49+00:00" />
<script type="application/ld+json">
{"@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/omr/proposal/omr/2019/11/28/proposal.html"},"url":"http://localhost:4000/omr/proposal/omr/2019/11/28/proposal.html","headline":"Proposal","dateModified":"2019-11-28T00:57:49+00:00","datePublished":"2019-11-28T00:57:49+00:00","description":"Background Composers, performers and musicians frequently want to make edits, comments, and changes to the sheet music. Doing so traditionally will produce hundreds or thousands of uncluttered pages of sheet music. Digital format is the perfect solution to better organize a collection of sheet music. It ensures replayability, enables large-scale musical theory analysis, and allows users to search for specific content systematically. Therefore, we present an end-to-end system to digitize music collection.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/omr/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/omr/feed.xml" title="Optical Music Recognition" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/omr/">Optical Music Recognition</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/omr/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Proposal</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2019-11-28T00:57:49+00:00" itemprop="datePublished">Nov 28, 2019
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h2 id="background">Background</h2>
<p>Composers, performers and musicians frequently want to make edits, comments, and changes to the sheet music. Doing so traditionally will produce hundreds or thousands of uncluttered pages of sheet music. Digital format is the perfect solution to better organize a collection of sheet music. It ensures replayability, enables large-scale musical theory analysis, and allows users to search for specific content systematically. Therefore, we present an end-to-end system to digitize music collection.</p>

<h2 id="current-status">Current Status</h2>
<h1 id="process">Process</h1>
<ol>
  <li>Preprocessing: contrast enhancement, binarization, noise removal, skew correction, etc.</li>
  <li>Object Detection: finding and classifying all relevant symbols in the image</li>
  <li>Musical Semantic Reconstruction: reconstruct logical relationship (e.g. between a notehead and a stem) and temporal relationship</li>
  <li>Encoding: encode to a MIDI or MusicXML format</li>
</ol>

<h1 id="previous-studies">Previous Studies</h1>
<ol>
  <li>Staff Line Removal: connected component analysis, <a href="https://github.com/ajgallego/staff-lines-removal">auto-encoders</a></li>
  <li>Bounding Box Prediction: <a href="https://ieeexplore.ieee.org/abstract/document/8395189">region-based CNN</a> (Faster R-CNN), <a href="http://ismir2018.ismir.net/doc/pdfs/175_Paper.pdf">semantic segmentation model</a> (U-Net), <a href="https://arxiv.org/abs/1805.10548">watershed semantic segmentation</a> (Deep Watershed)</li>
</ol>

<p>[
<img src="https://www.mdpi.com/applsci/applsci-08-01488/article_deploy/html/images/applsci-08-01488-g005.png" alt="DeepScores" width="230" height="300" />
|
<img src="https://www.mdpi.com/applsci/applsci-08-01488/article_deploy/html/images/applsci-08-01488-g006.png" alt="Muscima" width="230" height="300" /> 
|
<img src="https://www.mdpi.com/applsci/applsci-08-01488/article_deploy/html/images/applsci-08-01488-g007.png" alt="Capitan" width="230" height="300" />
]</p>

<p>Results in terms of mAP (%) and w-mAP (%) with respect to the dataset and object detector model following the COCO evaluation protocol.</p>

<table>
<thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" class="html-align-center"> </th><th colspan="3" align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" class="html-align-center">mAP (%)</th><th colspan="3" align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" class="html-align-center">w-mAP (%)</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" class="html-align-center"> </th><th align="center" valign="middle" style="border-bottom:solid thin" class="html-align-center">DeepScores</th><th align="center" valign="middle" style="border-bottom:solid thin" class="html-align-center">MUSCIMA++</th><th align="center" valign="middle" style="border-bottom:solid thin" class="html-align-center">Capitan</th><th align="center" valign="middle" style="border-bottom:solid thin" class="html-align-center">DeepScores</th><th align="center" valign="middle" style="border-bottom:solid thin" class="html-align-center">MUSCIMA++</th><th align="center" valign="middle" style="border-bottom:solid thin" class="html-align-center">Capitan</th></tr></thead><tbody><tr><td align="center" valign="middle" class="html-align-center"><b>Faster R-CNN</b></td><td align="center" valign="middle" class="html-align-center">19.6</td><td align="center" valign="middle" class="html-align-center">3.9</td><td align="center" valign="middle" class="html-align-center">15.2</td><td align="center" valign="middle" class="html-align-center">14.4</td><td align="center" valign="middle" class="html-align-center">7.9</td><td align="center" valign="middle" class="html-align-center">23.2</td></tr><tr><td align="center" valign="middle" class="html-align-center"><b>RetinaNet</b></td><td align="center" valign="middle" class="html-align-center">9.8</td><td align="center" valign="middle" class="html-align-center">7.7</td><td align="center" valign="middle" class="html-align-center">14.5</td><td align="center" valign="middle" class="html-align-center">1.9</td><td align="center" valign="middle" class="html-align-center">4.9</td><td align="center" valign="middle" class="html-align-center">34.9</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" class="html-align-center"><b>U-Net</b></td><td align="center" valign="middle" style="border-bottom:solid thin" class="html-align-center">24.8</td><td align="center" valign="middle" style="border-bottom:solid thin" class="html-align-center">16.6</td><td align="center" valign="middle" style="border-bottom:solid thin" class="html-align-center">17.4</td><td align="center" valign="middle" style="border-bottom:solid thin" class="html-align-center">23.3</td><td align="center" valign="middle" style="border-bottom:solid thin" class="html-align-center">33.6</td><td align="center" valign="middle" style="border-bottom:solid thin" class="html-align-center">26.0</td></tr></tbody>
</table>

<h1 id="challenges">Challenges</h1>
<ol>
  <li>Unbalanced dataset: rare symbols</li>
  <li>Notation variability</li>
  <li>Musical symbol isolation: multiple symbols could be connected to each other (e.g. a beam group) or a single unit can have multiple disconnected parts (e.g. vermata, voltas)</li>
  <li>High density of more than 1,000 objects in a single page</li>
</ol>

<h2 id="methods">Methods</h2>
<h1 id="dataset">Dataset</h1>
<ol>
  <li><a href="https://tuggeluk.github.io/deepscores/">DeepScores</a>: huge synthetic dataset in Common Western Modern Notation (CWMN), consisting of 300,000 images for performing symbol classification, image segmentation, and object detection</li>
  <li><a href="https://ufal.mff.cuni.cz/muscima">MUSCIMA++</a>: handwritten sheet music dataset in CWMN, consisting of over 90,000 images for symbol detection and symbol semantic relationships</li>
</ol>

<h2 id="reference">Reference</h2>

<ol>
  <li><a href="https://www.mdpi.com/2076-3417/8/9/1488">A Baseline for General Music Object Detection with Deep Learning</a></li>
  <li><a href="https://arxiv.org/pdf/1908.03608.pdf">Understanding Optical Music Recognition</a></li>
</ol>


  </div><a class="u-url" href="/omr/proposal/omr/2019/11/28/proposal.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/omr/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Optical Music Recognition</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Optical Music Recognition</li><li><a class="u-email" href="mailto:m_elsa@ymail.com">m_elsa@ymail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/melsaa"><svg class="svg-icon"><use xlink:href="/omr/assets/minima-social-icons.svg#github"></use></svg> <span class="username">melsaa</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>We transform sheet music into a digital format.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
